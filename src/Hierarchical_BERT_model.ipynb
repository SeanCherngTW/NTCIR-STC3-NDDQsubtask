{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import param\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import stctrain_bert\n",
    "import datahelper\n",
    "import stctokenizer\n",
    "import nuggetdetectionBERT as ND\n",
    "import dialogqualityBERT as DQ\n",
    "import dialogquality_ndfeatureBERT as DQNDF\n",
    "import stcevaluation as STCE\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2VecKeyedVectors object from ../embedding/STCWiki/STCWiki_mincount0.model.bin\n",
      "INFO:gensim.utils:loading vectors from ../embedding/STCWiki/STCWiki_mincount0.model.bin.vectors.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute vectors_norm to None\n",
      "INFO:gensim.utils:loaded ../embedding/STCWiki/STCWiki_mincount0.model.bin\n"
     ]
    }
   ],
   "source": [
    "doclen = param.doclen\n",
    "embsize = param.embsize\n",
    "max_sent = param.max_sent\n",
    "NDclasses = param.NDclasses\n",
    "DQclasses = param.DQclasses\n",
    "sentembsize = param.sentembsize\n",
    "\n",
    "REMOVE_STOPWORDS = False\n",
    "TO_LOWER = True\n",
    "TOKEN_TYPE = 'nltk'\n",
    "EMB = 'stc' # glove or stc\n",
    "\n",
    "datahelper = datahelper.DataHelper(embedding_path=\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "stctokenizer = stctokenizer.STCTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = datahelper.prepare_word_embedding_corpus(\n",
    "#     '../data/text8', \n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "# )\n",
    "\n",
    "# wordemb_model = Word2Vec(corpus, size=100, min_count=0, workers=4, iter=30, sg=1, window=5)\n",
    "# word_vectors = wordemb_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectors.save(\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "# datahelper.set_word_vectors(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Corpus & Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    _, trainX, trainND, trainDQ, train_turns, train_masks = datahelper.get_model_train_data(\n",
    "        'train',\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "        bert=False,\n",
    "    )\n",
    "\n",
    "    _, devX, devND, devDQ, dev_turns, dev_masks = datahelper.get_model_train_data(\n",
    "        'dev',\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "        bert=False,\n",
    "    )\n",
    "\n",
    "    _, testX,  test_turns, test_masks = datahelper.get_model_test_data(\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "        bert=False,\n",
    "    )\n",
    "    \n",
    "    trainX = pickle.load(open('PickleBert/trainX_bert_512.p', 'rb'))\n",
    "    devX = pickle.load(open('PickleBert/devX_bert_512.p', 'rb'))\n",
    "    testX = pickle.load(open('PickleBert/testX_bert_512.p', 'rb'))\n",
    "\n",
    "    testIDs = datahelper.testIDs\n",
    "    trainDQA = [item['A'] for item in trainDQ]\n",
    "    trainDQS = [item['S'] for item in trainDQ]\n",
    "    trainDQE = [item['E'] for item in trainDQ]\n",
    "    devDQA = [item['A'] for item in devDQ]\n",
    "    devDQS = [item['S'] for item in devDQ]\n",
    "    devDQE = [item['E'] for item in devDQ]\n",
    "\n",
    "    dataND = [trainX, trainND, train_turns, train_masks, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "    dataDQA = [trainX, trainDQA, train_turns, devX, devDQA, dev_turns, testX, test_turns]\n",
    "    dataDQS = [trainX, trainDQS, train_turns, devX, devDQS, dev_turns, testX, test_turns]\n",
    "    dataDQE = [trainX, trainDQE, train_turns, devX, devDQE, dev_turns, testX, test_turns]\n",
    "    \n",
    "    dataDQA_NDF = [trainX, trainDQA, train_turns, trainND, devX, devDQA, dev_turns, devND, testX, test_turns]\n",
    "    dataDQE_NDF = [trainX, trainDQE, train_turns, trainND, devX, devDQE, dev_turns, devND, testX, test_turns]\n",
    "    dataDQS_NDF = [trainX, trainDQS, train_turns, trainND, devX, devDQS, dev_turns, devND, testX, test_turns]\n",
    "\n",
    "    return dataND, dataDQA, dataDQE, dataDQS, dataDQA_NDF, dataDQE_NDF, dataDQS_NDF, testX, test_turns, test_masks, testIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:corpus word2vec:Unknown word: condition.\n",
      "INFO:corpus word2vec:Unknown word: `\n",
      "INFO:corpus word2vec:Unknown word: condition.\n",
      "INFO:corpus word2vec:Unknown word: `\n",
      "INFO:corpus word2vec:Unknown word: condition.\n",
      "INFO:corpus word2vec:Unknown word: `\n",
      "INFO:corpus word2vec:Training data unknown words count: 6\n",
      "INFO:corpus word2vec:Training data max doclen: 150\n",
      "INFO:corpus word2vec:Training data unknown words count: 0\n",
      "INFO:corpus word2vec:Training data max doclen: 150\n",
      "INFO:corpus word2vec:Testing data unknown words count: 0\n",
      "INFO:corpus word2vec:Testing data max doclen: 150\n"
     ]
    }
   ],
   "source": [
    "dataND, dataDQA, dataDQE, dataDQS, dataDQA_NDF, dataDQE_NDF, dataDQS_NDF, testX, test_turns, test_masks, testIDs = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (1337, 7, 1024)\n",
      "turns shape (1337,)\n",
      "masks shape (1337, 7, 7)\n",
      "X Example\n",
      "[[-0.38532966 -0.38864386 -0.42095938 ... -0.2239857   0.02487359\n",
      "  -0.05700535]\n",
      " [-0.21663742 -0.62647951 -0.35346892 ...  0.38286296 -0.02151336\n",
      "  -0.04521991]\n",
      " [-0.38483375 -0.20772332 -0.67306274 ...  0.08341745  0.0316062\n",
      "   0.09944315]\n",
      " ...\n",
      " [-0.25072855 -0.63722098 -0.60703731 ... -0.02940212  0.14081407\n",
      "  -0.38868326]\n",
      " [ 0.18198229 -0.45537627 -0.66125107 ...  0.09871428  0.47836649\n",
      "   0.03941095]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n",
      "turns Example\n",
      "6\n",
      "masks Example\n",
      "[[1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape\", np.array(dataND[0]).shape)\n",
    "print(\"turns shape\", np.array(dataND[2]).shape)\n",
    "print(\"masks shape\", np.array(dataND[3]).shape)\n",
    "\n",
    "print(\"X Example\")\n",
    "print(dataND[0][0])\n",
    "\n",
    "print(\"turns Example\")\n",
    "print(dataND[2][0])\n",
    "\n",
    "print(\"masks Example\")\n",
    "print(dataND[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 3\n",
    "fixed_paramsND  = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':30,\n",
    "    'lr':5e-4,\n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,3], \n",
    "    'gating':False, \n",
    "    'bn':True, \n",
    "    'method':ND.CNNRNN,\n",
    "} \n",
    "\n",
    "fixed_paramsDQ = {\n",
    "    'epoch':50, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':40, \n",
    "    'lr':5e-4, \n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,2],\n",
    "    'gating':True, \n",
    "    'bn':True, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def show_train_history(title, train, valid, earlystop=es):\n",
    "    epoch = len(train)\n",
    "    best = epoch-earlystop\n",
    "    x = [i for i in range(1, epoch + 1)]\n",
    "    plt.figure(figsize=(5,12))\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.plot(x, train, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(x, valid, marker='o', linestyle='-', color='r')\n",
    "    plt.axvline(best, color='black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = 'PickleResult/'\n",
    "# bestND = pickle.load(open(BEST_PATH + 'bestND.p', \"rb\"))\n",
    "bestDQAs = pickle.load(open(BEST_PATH + 'memoryDQAs.p', \"rb\"))\n",
    "bestDQSs = pickle.load(open(BEST_PATH + 'memoryDQSs.p', \"rb\"))\n",
    "bestDQEs = pickle.load(open(BEST_PATH + 'memoryDQEs.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDsubtask-BERT-LSTM\n",
      "Start epoch 0\n",
      "Start epoch 1\n",
      "Start epoch 2\n",
      "Start epoch 3\n",
      "Start epoch 4\n",
      "Start epoch 5\n",
      "Start epoch 6\n",
      "Start epoch 7\n",
      "Start epoch 8\n",
      "Start epoch 9\n",
      "Start epoch 10\n",
      "Start epoch 11\n",
      "CNNRNN|12|False|True|2_3|1024|256|1|0.0261|0.0957\n",
      "models/ND/NDsubtask.ckpt is saved\n",
      "\n",
      "SavedModel\n"
     ]
    }
   ],
   "source": [
    "e = True\n",
    "for mr in [None]:\n",
    "    for fn in [[256]]:\n",
    "        for num_layers in [2]:\n",
    "            testname = 'NDsubtask-BERT-LSTM'\n",
    "            print(testname)\n",
    "            testND, train_losses, dev_losses = stctrain_bert.start_trainND(\n",
    "                *dataND, \n",
    "                **fixed_paramsND,\n",
    "                Fnum=fn, num_layers=num_layers, memory_rnn_type=mr,\n",
    "                evaluate=e\n",
    "            )\n",
    "\n",
    "    #             show_train_history(testname, train_losses, dev_losses)\n",
    "            datahelper.pred_to_submission(testND, bestDQAs[0], bestDQSs[0], bestDQEs[0], test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(testND, open('bestND190116.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('PickleResult/memoryNDs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bestDQA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ae559635bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatahelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_to_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestDQA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestDQS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestDQE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_turns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestIDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}.json'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bestDQA' is not defined"
     ]
    }
   ],
   "source": [
    "datahelper.pred_to_submission(testND, bestDQA, bestDQS, bestDQE, test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = True\n",
    "method = DQ.CNNCNN\n",
    "for l in [1]:\n",
    "    for rm in ['Bi-GRU']:\n",
    "        for fn in [[512, 1024]]:\n",
    "            testname = 'DQsubtask-MeGCBERT'\n",
    "            print(testname, 'is started')\n",
    "        \n",
    "            bestDQA, train_lossesA, dev_lossesA = stctrain_bert.start_trainDQ(\n",
    "                *dataDQA, \n",
    "                **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "            bestDQE, train_lossesE, dev_lossesE = stctrain_bert.start_trainDQ(\n",
    "                *dataDQE, \n",
    "                **fixed_paramsDQ, scoretype='DQE', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "            bestDQS, train_lossesS, dev_lossesS = stctrain_bert.start_trainDQ(\n",
    "                *dataDQS, \n",
    "                **fixed_paramsDQ, scoretype='DQS', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e\n",
    "            )\n",
    "\n",
    "            \n",
    "            datahelper.pred_to_submission(testND, bestDQA, bestDQS, bestDQE, test_turns, testIDs, filename='{}.json'.format(testname))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQAs, open('memoryDQAs.p', 'wb'))\n",
    "# pickle.dump(bestDQSs, open('memoryDQSs.p', 'wb'))\n",
    "# pickle.dump(bestDQEs, open('memoryDQEs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_to_pred(path='ReTesting/0220_wordemb_test/NoneMemory_3stackCNN_2stackRNN(best).json'):\n",
    "    import json\n",
    "    with open(path) as f:\n",
    "        test_preds_json = json.load(f)\n",
    "        \n",
    "    pred = []\n",
    "    \n",
    "    for testID in testIDs:\n",
    "        for test_pred_json in test_preds_json:\n",
    "            _id = test_pred_json['id']\n",
    "            if _id != testID:\n",
    "                continue\n",
    "            dialogue_nuggets = test_pred_json['nugget']\n",
    "            dialogue_pred = [] \n",
    "            \n",
    "            for utterance_nugget in dialogue_nuggets:\n",
    "                utterance_pred = [None] * 7\n",
    "                if len(utterance_nugget.keys()) == 4:\n",
    "                    utterance_pred[0] = utterance_nugget['CNUG*']\n",
    "                    utterance_pred[1] = utterance_nugget['CNUG']\n",
    "                    utterance_pred[2] = utterance_nugget['CNaN']\n",
    "                    utterance_pred[3] = utterance_nugget['CNUG0']\n",
    "                    utterance_pred[4] = 0.\n",
    "                    utterance_pred[5] = 0.\n",
    "                    utterance_pred[6] = 0.\n",
    "                elif len(utterance_nugget.keys()) == 3:\n",
    "                    utterance_pred[0] = 0.\n",
    "                    utterance_pred[1] = 0.\n",
    "                    utterance_pred[2] = 0.\n",
    "                    utterance_pred[3] = 0.\n",
    "                    utterance_pred[4] = utterance_nugget['HNUG*']\n",
    "                    utterance_pred[5] = utterance_nugget['HNUG']\n",
    "                    utterance_pred[6] = utterance_nugget['HNaN']\n",
    "                \n",
    "                dialogue_pred.append(utterance_pred)\n",
    "                \n",
    "            while len(dialogue_pred) < 7:\n",
    "                dialogue_pred.append([0] * 7)\n",
    "                \n",
    "            pred.append(dialogue_pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testND = submission_to_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNDmasked = [np.multiply(nd, mask) for nd, mask in zip(testND, test_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDQA_NDF += [testNDmasked]\n",
    "dataDQE_NDF += [testNDmasked]\n",
    "dataDQS_NDF += [testNDmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeGCBERT1 is started\n",
      "Start epoch 0\n",
      "Start epoch 1\n",
      "Start epoch 2\n",
      "Start epoch 3\n",
      "Start epoch 4\n",
      "Start epoch 5\n",
      "Start epoch 6\n",
      "CNNCNN|7|True|True|2_2|1024|512_1024|0.08459|0.12972\n",
      "models/DQDQA/DQsubtask-DQAscore.ckpt is saved\n",
      "\n",
      "Start epoch 0\n",
      "Start epoch 1\n",
      "Start epoch 2\n",
      "Start epoch 3\n",
      "Start epoch 4\n",
      "Start epoch 5\n",
      "Start epoch 6\n",
      "CNNCNN|7|True|True|2_2|1024|512_1024|0.08111|0.12309\n",
      "models/DQDQE/DQsubtask-DQEscore.ckpt is saved\n",
      "\n",
      "Start epoch 0\n",
      "Start epoch 1\n",
      "Start epoch 2\n",
      "Start epoch 3\n",
      "Start epoch 4\n",
      "Start epoch 5\n",
      "Start epoch 6\n",
      "Start epoch 7\n",
      "Start epoch 8\n",
      "CNNCNN|9|True|True|2_2|1024|512_1024|0.07695|0.12355\n",
      "models/DQDQS/DQsubtask-DQSscore.ckpt is saved\n",
      "\n",
      "MeGCBERT2 is started\n",
      "Start epoch 0\n",
      "Start epoch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bac85e334234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mfixed_paramsDQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoretype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DQA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mFnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_rnn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/CodeWorkspace/NTCIR-STC3-NDDQsubtask/src/stctrain_bert.py\u001b[0m in \u001b[0;36mstart_trainDQ_NDF\u001b[0;34m(trainX, trainY, train_turns, trainND, devX, devY, dev_turns, devND, testX, test_turns, testND, scoretype, epoch, early_stopping, batch_size, lr, kp, hiddens, Fsize, Fnum, gating, bn, num_layers, method, evaluate, memory_rnn_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0mtrain_bs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen_train\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 sess.run(train_op, feed_dict={x: trainX[i:j], y: trainY[i:j], bs: train_bs,\n\u001b[0;32m--> 301\u001b[0;31m                                               turns: train_turns[i:j], num_dialog: len_train, nd: trainND[i:j]})\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;31m# Compute train loss in batch since memory is not enough\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "method = DQNDF.CNNCNN\n",
    "e = True\n",
    "testND = np.asarray(testND)\n",
    "\n",
    "testnameORG = 'MeGCBERT'\n",
    "for i in range(1):\n",
    "    for mr in ['Bi-GRU']:\n",
    "        for fnum in [[512, 1024]]:\n",
    "            for num_layers in [1]:\n",
    "                testname = testnameORG + str(i+1)\n",
    "                print(testname, 'is started')\n",
    "                bestDQNDFA, train_lossesA, dev_lossesA = stctrain_bert.start_trainDQ_NDF(\n",
    "                    *dataDQA_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                    Fnum=fnum, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e,\n",
    "                )\n",
    "\n",
    "                bestDQNDFE, train_lossesE, dev_lossesE = stctrain_bert.start_trainDQ_NDF(\n",
    "                    *dataDQE_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQE',\n",
    "                    Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e,\n",
    "                )\n",
    "\n",
    "                bestDQNDFS, train_lossesS, dev_lossesS = stctrain_bert.start_trainDQ_NDF(\n",
    "                    *dataDQS_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQS', \n",
    "                    Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e,\n",
    "                )\n",
    "\n",
    "                datahelper.pred_to_submission(testND, bestDQNDFA, bestDQNDFS, bestDQNDFE, test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQANDFs, open('memoryDQANDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQSNDFs, open('memoryDQSNDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQENDFs, open('memoryDQENDFs.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
