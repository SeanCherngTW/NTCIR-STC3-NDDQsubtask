{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import param\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import stctrainCRF\n",
    "import datahelperCRF\n",
    "import stctokenizer\n",
    "import nuggetdetectionCRF as ND\n",
    "# import dialogquality as DQ\n",
    "# import dialogquality_ndfeature as DQNDF\n",
    "import stcevaluation as STCE\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclen = param.doclen\n",
    "embsize = param.embsize\n",
    "max_sent = param.max_sent\n",
    "NDclasses = param.NDclasses\n",
    "DQclasses = param.DQclasses\n",
    "sentembsize = param.sentembsize\n",
    "\n",
    "REMOVE_STOPWORDS = False\n",
    "TO_LOWER = True\n",
    "TOKEN_TYPE = 'nltk'\n",
    "EMB = 'stc' # glove or stc\n",
    "\n",
    "datahelper = datahelperCRF.DataHelper(embedding_path=\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "stctokenizer = stctokenizer.STCTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = datahelper.prepare_word_embedding_corpus(\n",
    "#     '../data/text8', \n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "# )\n",
    "\n",
    "# wordemb_model = Word2Vec(corpus, size=100, min_count=0, workers=4, iter=30, sg=1, window=5)\n",
    "# word_vectors = wordemb_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectors.save(\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "# datahelper.set_word_vectors(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Corpus & Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data():\n",
    "isBERT = False\n",
    "trainX, _, trainND, trainDQ, train_turns, train_masks = datahelper.get_model_train_data(\n",
    "    'train',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=isBERT,\n",
    ")\n",
    "\n",
    "devX, _, devND, devDQ, dev_turns, dev_masks = datahelper.get_model_train_data(\n",
    "    'dev',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=isBERT,\n",
    ")\n",
    "\n",
    "testX, _, testND, testDQ, test_turns, test_masks = datahelper.get_model_train_data(\n",
    "    'test',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=isBERT,\n",
    ")\n",
    "\n",
    "# testX, _, test_turns, test_masks = datahelper.get_model_test_data(\n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "#     EMB,\n",
    "#     bert=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "MultiAnsUtt = namedtuple(\"MultiAnsUtt\", ['uttidx', 'secondans'])\n",
    "\n",
    "def highest_label_idx(prob):\n",
    "    highest = np.max(prob)\n",
    "    return np.where(prob==highest)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_second_ans(uttidx, second_ansidx, CRFX, CRFND, CRFTurns, CRFMasks, CRFDialogND, dialogX, dialogTurn, dialogMask):\n",
    "    global max_sent\n",
    "    CRF_label = np.asarray([0.] * max_sent)\n",
    "    CRF_label[second_ansidx] = 1.\n",
    "    CRFDialogND[uttidx] = CRF_label\n",
    "    CRFX.append(dialogX)\n",
    "    CRFND.append(CRFDialogND.copy())\n",
    "    CRFTurns.append(dialogTurn)\n",
    "    CRFMasks.append(dialogMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCRF(X, ND, turns, masks):\n",
    "    CRFX = []\n",
    "    CRFND = []\n",
    "    CRFTurns = []\n",
    "    CRFMasks = []\n",
    "    for dialogidx, (dialogX, dialogND, dialogTurn, dialogMask) in enumerate(zip(X, ND, turns, masks)):\n",
    "        multi_ans_uttidx = []\n",
    "        CRFDialogND = []\n",
    "\n",
    "        for uttidx, (uttX, uttND, uttMask) in enumerate(zip(dialogX, dialogND, dialogMask)):\n",
    "            ans_idx = highest_label_idx(uttND)\n",
    "            num_of_ans = len(ans_idx)\n",
    "            CRF_label = np.asarray([0.] * max_sent)\n",
    "            if num_of_ans == 7:  # all zero\n",
    "                CRFDialogND.append(CRF_label)\n",
    "            elif num_of_ans == 1:  # one ans\n",
    "                CRF_label[ans_idx[0]] = 1.\n",
    "                CRFDialogND.append(CRF_label)\n",
    "            elif num_of_ans == 2:  # two ans\n",
    "                CRF_label[ans_idx[0]] = 1.\n",
    "                CRFDialogND.append(CRF_label)\n",
    "                multi_ans_uttidx.append(MultiAnsUtt(uttidx, ans_idx[1]))  # save the second ans and add later\n",
    "            else:\n",
    "                assert False, 'ND ans with more than 2'\n",
    "\n",
    "        CRFX.append(dialogX)\n",
    "        CRFND.append(CRFDialogND.copy())\n",
    "        CRFTurns.append(dialogTurn)\n",
    "        CRFMasks.append(dialogMask)\n",
    "\n",
    "        if len(multi_ans_uttidx) == 1:\n",
    "            uttidx, second_ansidx = multi_ans_uttidx[0]\n",
    "            add_second_ans(uttidx, second_ansidx, CRFX, CRFND, CRFTurns, CRFMasks, CRFDialogND.copy(), dialogX, dialogTurn, dialogMask)\n",
    "\n",
    "        elif len(multi_ans_uttidx) == 2:\n",
    "            uttidx0, second_ansidx0 = multi_ans_uttidx[0]\n",
    "            uttidx1, second_ansidx1 = multi_ans_uttidx[1]\n",
    "\n",
    "            # 1st ans & 1st ans is already in the final list\n",
    "\n",
    "            # 1st ans & 2nd ans\n",
    "            add_second_ans(uttidx1, second_ansidx1, CRFX, CRFND, CRFTurns, CRFMasks, CRFDialogND.copy(), dialogX, dialogTurn, dialogMask)\n",
    "            # 2nd ans & 1st ans\n",
    "            add_second_ans(uttidx0, second_ansidx0, CRFX, CRFND, CRFTurns, CRFMasks, CRFDialogND, dialogX, dialogTurn, dialogMask)\n",
    "            # 2nd ans & 2nd ans\n",
    "            add_second_ans(uttidx1, second_ansidx1, CRFX, CRFND, CRFTurns, CRFMasks, CRFDialogND, dialogX, dialogTurn, dialogMask)\n",
    "    \n",
    "    assert len(CRFX) == len(CRFND) == len(CRFTurns) == len(CRFMasks)\n",
    "    return CRFX, CRFND, CRFTurns, CRFMasks\n",
    "\n",
    "def convertCRF_test(testND):\n",
    "    idx_test_ND = []\n",
    "    for i in range(len(testND)):\n",
    "        idx_test_ND_dialog = []\n",
    "        for j in range(max_sent):\n",
    "            if np.all(testND[i][j] == 0):\n",
    "                idx_test_ND_dialog.append(7)\n",
    "            else:\n",
    "                idx = highest_label_idx(testND[i][j])\n",
    "                if len(idx) == 1:\n",
    "                    idx_test_ND_dialog.append(idx[0])\n",
    "                else:\n",
    "                    idx_test_ND_dialog.append(idx)\n",
    "        idx_test_ND.append(idx_test_ND_dialog.copy())\n",
    "    return idx_test_ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_to_index(CRFND):\n",
    "    for i in range(len(CRFND)):\n",
    "        for j in range(max_sent):\n",
    "            if np.all(CRFND[i][j] == 0):\n",
    "                CRFND[i][j] = 7\n",
    "            else:\n",
    "                CRFND[i][j] = np.argmax(CRFND[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRFtrainX, CRFtrainND, CRFtrain_turns, CRFtrain_masks = convertCRF(trainX, trainND, train_turns, train_masks)\n",
    "CRFdevX, CRFdevND, CRFdev_turns, CRFdev_masks = convertCRF(devX, devND, dev_turns, dev_masks)\n",
    "\n",
    "convert_label_to_index(CRFtrainND)\n",
    "convert_label_to_index(CRFdevND)\n",
    "CRFtestND = convertCRF_test(testND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1337, 5601, 335, 1316)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_turns), sum(train_turns), len(dev_turns), sum(dev_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 6150, 368, 1461)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CRFtrain_turns), sum(CRFtrain_turns), len(CRFdev_turns), sum(CRFdev_turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(CRFtestND[10][5], np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on 1 dialogue with 2 ans in 1 utterance\n",
      "Test on 1 dialogue with 2 ans in 2 utterances\n",
      "PASS\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print('Test on 1 dialogue with 2 ans in 1 utterance')\n",
    "i = 14\n",
    "CRFi = 14\n",
    "# pprint(trainND[i])\n",
    "# pprint(CRFtrainND[CRFi])\n",
    "# pprint(CRFtrainND[CRFi+1])\n",
    "assert(CRFtrainX[CRFi].all() == CRFtrainX[CRFi+1].all())\n",
    "assert(CRFtrain_turns[CRFi] == CRFtrain_turns[CRFi+1])\n",
    "assert(CRFtrain_masks[CRFi].all() == CRFtrain_masks[CRFi+1].all())\n",
    "# print()\n",
    "i = 15\n",
    "CRFi = 16\n",
    "# pprint(trainND[i])\n",
    "# pprint(CRFtrainND[CRFi])\n",
    "# pprint(CRFtrainND[CRFi+1])\n",
    "# print()\n",
    "\n",
    "print('Test on 1 dialogue with 2 ans in 2 utterances')\n",
    "i = 101\n",
    "# pprint(trainND[i])\n",
    "CRFi = 110\n",
    "# pprint(CRFtrainND[CRFi])\n",
    "# pprint(CRFtrainND[CRFi+1])\n",
    "# pprint(CRFtrainND[CRFi+2])\n",
    "# pprint(CRFtrainND[CRFi+3])\n",
    "assert(CRFtrainX[CRFi].all() == CRFtrainX[CRFi+1].all() == CRFtrainX[CRFi+2].all() == CRFtrainX[CRFi+3].all())\n",
    "assert(CRFtrain_turns[CRFi] == CRFtrain_turns[CRFi+1] == CRFtrain_turns[CRFi+2] == CRFtrain_turns[CRFi+3])\n",
    "assert(CRFtrain_masks[CRFi].all() == CRFtrain_masks[CRFi+1].all() == CRFtrain_masks[CRFi+2].all() == CRFtrain_masks[CRFi+3].all())\n",
    "\n",
    "print('PASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIDs = datahelper.testIDs\n",
    "# trainDQA = [item['A'] for item in trainDQ]\n",
    "# trainDQS = [item['S'] for item in trainDQ]\n",
    "# trainDQE = [item['E'] for item in trainDQ]\n",
    "# devDQA = [item['A'] for item in devDQ]\n",
    "# devDQS = [item['S'] for item in devDQ]\n",
    "# devDQE = [item['E'] for item in devDQ]\n",
    "\n",
    "dataND = [CRFtrainX, CRFtrainND, CRFtrain_turns, CRFtrain_masks, CRFdevX, CRFdevND, CRFdev_turns, CRFdev_masks, testX, CRFtestND, test_turns, test_masks]\n",
    "# dataDQA = [trainX, trainDQA, train_turns, devX, devDQA, dev_turns, testX, test_turns]\n",
    "# dataDQS = [trainX, trainDQS, train_turns, devX, devDQS, dev_turns, testX, test_turns]\n",
    "# dataDQE = [trainX, trainDQE, train_turns, devX, devDQE, dev_turns, testX, test_turns]\n",
    "\n",
    "# dataDQA_NDF = [trainX, trainDQA, train_turns, trainND, devX, devDQA, dev_turns, devND, testX, test_turns]\n",
    "# dataDQE_NDF = [trainX, trainDQE, train_turns, trainND, devX, devDQE, dev_turns, devND, testX, test_turns]\n",
    "# dataDQS_NDF = [trainX, trainDQS, train_turns, trainND, devX, devDQS, dev_turns, devND, testX, test_turns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter({0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0})\n",
    "for sent in CRFdevND:\n",
    "    counter += Counter(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 1337, 368, 335)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CRFtrainX), len(trainX), len(CRFdevX), len(devX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 7, 150, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(CRFtrainX).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(CRFtrainND).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 3\n",
    "fixed_paramsND  = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':30,\n",
    "    'lr':5e-4,\n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,3], \n",
    "    'gating':False, \n",
    "    'bn':True, \n",
    "    'method':ND.CNNRNN,\n",
    "} \n",
    "\n",
    "fixed_paramsDQ = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':40, \n",
    "    'lr':5e-4, \n",
    "    'kp':1, \n",
    "    'hiddens':1024, # 1024 for gating, 2048 for no gating\n",
    "    'Fsize':[2,2], # [2,2] for gating, [2,3] for no gating\n",
    "    'gating':True, \n",
    "    'bn':True, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def show_train_history(title, train, valid, earlystop=es):\n",
    "    epoch = len(train)\n",
    "    best = epoch-earlystop\n",
    "    x = [i for i in range(1, epoch + 1)]\n",
    "    plt.figure(figsize=(5,12))\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.plot(x, train, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(x, valid, marker='o', linestyle='-', color='r')\n",
    "    plt.axvline(best, color='black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = 'PickleResult/'\n",
    "# bestND = pickle.load(open(BEST_PATH + 'bestND.p', \"rb\"))\n",
    "bestDQAs = pickle.load(open(BEST_PATH + 'memoryDQAs.p', \"rb\"))\n",
    "bestDQSs = pickle.load(open(BEST_PATH + 'memoryDQSs.p', \"rb\"))\n",
    "bestDQEs = pickle.load(open(BEST_PATH + 'memoryDQEs.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e = True\n",
    "for mr in [None, 'Bi-GRU', 'Bi-LSTM']:\n",
    "    for fn in [[256], [256,512], [256,512,1024]]:\n",
    "        for num_layers in [1, 2, 3]:\n",
    "#                 trainXp = trainX[:int(train_len/10*prop)]\n",
    "#                 trainNDp = trainND[:int(train_len/10*prop)]\n",
    "#                 train_turnsp = train_turns[:int(train_len/10*prop)]\n",
    "#                 train_masksp = train_masks[:int(train_len/10*prop)]\n",
    "#                 dataND = [trainXp, trainNDp, train_turnsp, train_masksp, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "\n",
    "            testname = 'ND_BERT_CRF_Memory{}_CNN{}_RNN{}'.format(mr, len(fn), num_layers)\n",
    "            testND, train_losses, dev_losses = stctrainCRF.start_trainND(\n",
    "                *dataND, \n",
    "                **fixed_paramsND,\n",
    "                Fnum=fn, num_layers=num_layers, memory_rnn_type=mr,\n",
    "                evaluate=e,\n",
    "                bert=1,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_losses, dev_losses)\n",
    "#             datahelper.pred_to_submission(testND, bestDQAs[0], bestDQSs[0], bestDQEs[0], test_turns, testIDs, filename='{}.json'.format(testname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(testND, open('bestND190116.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('PickleResult/memoryNDs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainDQA, train_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = True\n",
    "method = DQ.CNNCNN\n",
    "for l in [1]:\n",
    "    for rm in ['Bi-LSTM']:\n",
    "        for fn in [[512, 1024]]:\n",
    "            testname = 'ND_trainsize_{}perc'.format(prop*10)\n",
    "            print(testname, 'is started')\n",
    "        \n",
    "            bestDQA, train_lossesA, dev_lossesA = stctrain.start_trainDQ(\n",
    "                *dataDQA, \n",
    "                **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "            \n",
    "\n",
    "            bestDQE, train_lossesE, dev_lossesE = stctrain.start_trainDQ(\n",
    "                *dataDQE, \n",
    "                **fixed_paramsDQ, scoretype='DQE', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "            bestDQS, train_lossesS, dev_lossesS = stctrain.start_trainDQ(\n",
    "                *dataDQS, \n",
    "                **fixed_paramsDQ, scoretype='DQS', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e\n",
    "            )\n",
    "       \n",
    "            datahelper.pred_to_submission(memoryNDs[0], bestDQA, bestDQS, bestDQE, test_turns, testIDs, filename='{}.json'.format(testname))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQAs, open('memoryDQAs.p', 'wb'))\n",
    "# pickle.dump(bestDQSs, open('memoryDQSs.p', 'wb'))\n",
    "# pickle.dump(bestDQEs, open('memoryDQEs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_to_pred(path='ReTesting/0220_wordemb_test/NoneMemory_3stackCNN_2stackRNN(best).json'):\n",
    "    import json\n",
    "    with open(path) as f:\n",
    "        test_preds_json = json.load(f)\n",
    "        \n",
    "    pred = []\n",
    "    \n",
    "    for testID in testIDs:\n",
    "        for test_pred_json in test_preds_json:\n",
    "            _id = test_pred_json['id']\n",
    "            if _id != testID:\n",
    "                continue\n",
    "            dialogue_nuggets = test_pred_json['nugget']\n",
    "            dialogue_pred = [] \n",
    "            \n",
    "            for utterance_nugget in dialogue_nuggets:\n",
    "                utterance_pred = [None] * 7\n",
    "                if len(utterance_nugget.keys()) == 4:\n",
    "                    utterance_pred[0] = utterance_nugget['CNUG*']\n",
    "                    utterance_pred[1] = utterance_nugget['CNUG']\n",
    "                    utterance_pred[2] = utterance_nugget['CNaN']\n",
    "                    utterance_pred[3] = utterance_nugget['CNUG0']\n",
    "                    utterance_pred[4] = 0.\n",
    "                    utterance_pred[5] = 0.\n",
    "                    utterance_pred[6] = 0.\n",
    "                elif len(utterance_nugget.keys()) == 3:\n",
    "                    utterance_pred[0] = 0.\n",
    "                    utterance_pred[1] = 0.\n",
    "                    utterance_pred[2] = 0.\n",
    "                    utterance_pred[3] = 0.\n",
    "                    utterance_pred[4] = utterance_nugget['HNUG*']\n",
    "                    utterance_pred[5] = utterance_nugget['HNUG']\n",
    "                    utterance_pred[6] = utterance_nugget['HNaN']\n",
    "                \n",
    "                dialogue_pred.append(utterance_pred)\n",
    "                \n",
    "            while len(dialogue_pred) < 7:\n",
    "                dialogue_pred.append([0] * 7)\n",
    "                \n",
    "            pred.append(dialogue_pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testND = submission_to_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNDmasked = [np.multiply(nd, mask) for nd, mask in zip(testND, test_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDQA_NDF += [testNDmasked]\n",
    "dataDQE_NDF += [testNDmasked]\n",
    "dataDQS_NDF += [testNDmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataDQA_NDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = DQNDF.CNNCNN\n",
    "e = True\n",
    "testND = np.asarray(testND)\n",
    "\n",
    "# for prop in range(1, 11):\n",
    "for mr in ['Bi-LSTM']:\n",
    "    for fnum in [[512, 1024]]:\n",
    "        for num_layers in [1]:\n",
    "            testname = 'test'\n",
    "            print(testname, 'is started')\n",
    "\n",
    "#             trainXp = trainX[:int(train_len/10*prop)]\n",
    "#             train_turnsp = train_turns[:int(train_len/10*prop)]\n",
    "#             trainNDp = trainND[:int(train_len/10*prop)]\n",
    "\n",
    "#             trainDQAp = trainDQA[:int(train_len/10*prop)]      \n",
    "#             dataDQA_NDF = [trainXp, trainDQAp, train_turnsp, trainNDp, devX, devDQA, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "#             trainDQEp = trainDQE[:int(train_len/10*prop)]         \n",
    "#             dataDQE_NDF = [trainXp, trainDQEp, train_turnsp, trainNDp, devX, devDQE, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "#             trainDQSp = trainDQA[:int(train_len/10*prop)]              \n",
    "#             dataDQS_NDF = [trainXp, trainDQSp, train_turnsp, trainNDp, devX, devDQS, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "\n",
    "\n",
    "            bestDQNDFA, train_lossesA, dev_lossesA = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQA_NDF, \n",
    "                **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                Fnum=fnum, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                evaluate=e, bert=False,\n",
    "            )\n",
    "\n",
    "            bestDQNDFE, train_lossesE, dev_lossesE = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQE_NDF, \n",
    "                **fixed_paramsDQ, scoretype='DQE',\n",
    "                Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                evaluate=e, bert=False,\n",
    "            )\n",
    "\n",
    "            bestDQNDFS, train_lossesS, dev_lossesS = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQS_NDF, \n",
    "                **fixed_paramsDQ, scoretype='DQS', \n",
    "                Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                evaluate=e, bert=False,\n",
    "            )\n",
    "\n",
    "            datahelper.pred_to_submission(testND, bestDQNDFA, bestDQNDFS, bestDQNDFE, test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQANDFs, open('memoryDQANDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQSNDFs, open('memoryDQSNDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQENDFs, open('memoryDQENDFs.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
