{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import param\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import stctrain\n",
    "import datahelper\n",
    "import stctokenizer\n",
    "import nuggetdetection as ND\n",
    "import dialogquality as DQ\n",
    "import dialogquality_ndfeature as DQNDF\n",
    "import stcevaluation as STCE\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclen = param.doclen\n",
    "embsize = param.embsize\n",
    "max_sent = param.max_sent\n",
    "NDclasses = param.NDclasses\n",
    "DQclasses = param.DQclasses\n",
    "sentembsize = param.sentembsize\n",
    "\n",
    "REMOVE_STOPWORDS = False\n",
    "TO_LOWER = True\n",
    "TOKEN_TYPE = 'nltk'\n",
    "EMB = 'stc' # glove or stc\n",
    "\n",
    "datahelper = datahelper.DataHelper(embedding_path=\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "stctokenizer = stctokenizer.STCTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = datahelper.prepare_word_embedding_corpus(\n",
    "#     '../data/text8', \n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "# )\n",
    "\n",
    "# wordemb_model = Word2Vec(corpus, size=100, min_count=0, workers=4, iter=30, sg=1, window=5)\n",
    "# word_vectors = wordemb_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectors.save(\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "# datahelper.set_word_vectors(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Corpus & Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data():\n",
    "trainX, _, trainND, trainDQ, train_turns, train_masks = datahelper.get_model_train_data(\n",
    "    'train',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=False,\n",
    ")\n",
    "\n",
    "devX, _, devND, devDQ, dev_turns, dev_masks = datahelper.get_model_train_data(\n",
    "    'dev',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=False,\n",
    ")\n",
    "\n",
    "testX, _, test_turns, test_masks = datahelper.get_model_test_data(\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    "    EMB,\n",
    "    bert=False,\n",
    ")\n",
    "\n",
    "testIDs = datahelper.testIDs\n",
    "trainDQA = [item['A'] for item in trainDQ]\n",
    "trainDQS = [item['S'] for item in trainDQ]\n",
    "trainDQE = [item['E'] for item in trainDQ]\n",
    "devDQA = [item['A'] for item in devDQ]\n",
    "devDQS = [item['S'] for item in devDQ]\n",
    "devDQE = [item['E'] for item in devDQ]\n",
    "\n",
    "dataND = [trainX, trainND, train_turns, train_masks, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "dataDQA = [trainX, trainDQA, train_turns, devX, devDQA, dev_turns, testX, test_turns]\n",
    "dataDQS = [trainX, trainDQS, train_turns, devX, devDQS, dev_turns, testX, test_turns]\n",
    "dataDQE = [trainX, trainDQE, train_turns, devX, devDQE, dev_turns, testX, test_turns]\n",
    "\n",
    "dataDQA_NDF = [trainX, trainDQA, train_turns, trainND, devX, devDQA, dev_turns, devND, testX, test_turns]\n",
    "dataDQE_NDF = [trainX, trainDQE, train_turns, trainND, devX, devDQE, dev_turns, devND, testX, test_turns]\n",
    "dataDQS_NDF = [trainX, trainDQS, train_turns, trainND, devX, devDQS, dev_turns, devND, testX, test_turns]\n",
    "\n",
    "# return dataND, dataDQA, dataDQE, dataDQS, dataDQA_NDF, dataDQE_NDF, dataDQS_NDF, testX, test_turns, test_masks, testIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataND, dataDQA, dataDQE, dataDQS, dataDQA_NDF, dataDQE_NDF, dataDQS_NDF, testX, test_turns, test_masks, testIDs = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = 3\n",
    "fixed_paramsND  = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':30,\n",
    "    'lr':5e-4,\n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,3], \n",
    "    'gating':False, \n",
    "    'bn':True, \n",
    "    'method':ND.CNNRNN,\n",
    "} \n",
    "\n",
    "fixed_paramsDQ = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':40, \n",
    "    'lr':5e-4, \n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,2],\n",
    "    'gating':True, \n",
    "    'bn':True, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def show_train_history(title, train, valid, earlystop=es):\n",
    "    epoch = len(train)\n",
    "    best = epoch-earlystop\n",
    "    x = [i for i in range(1, epoch + 1)]\n",
    "    plt.figure(figsize=(5,12))\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.plot(x, train, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(x, valid, marker='o', linestyle='-', color='r')\n",
    "    plt.axvline(best, color='black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATH = 'ResultPickle/'\n",
    "# bestND = pickle.load(open(BEST_PATH + 'bestND.p', \"rb\"))\n",
    "bestDQAs = pickle.load(open(BEST_PATH + 'memoryDQAs.p', \"rb\"))\n",
    "bestDQSs = pickle.load(open(BEST_PATH + 'memoryDQSs.p', \"rb\"))\n",
    "bestDQEs = pickle.load(open(BEST_PATH + 'memoryDQEs.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|13|False|True|2_3|1024|256_512_1024|1|0.0248|0.0939\n"
     ]
    }
   ],
   "source": [
    "e = True\n",
    "for mr in [None]:\n",
    "    for fn in [[256,512,1024]]:\n",
    "        for num_layers in [2]:\n",
    "#                 trainXp = trainX[:int(train_len/10*prop)]\n",
    "#                 trainNDp = trainND[:int(train_len/10*prop)]\n",
    "#                 train_turnsp = train_turns[:int(train_len/10*prop)]\n",
    "#                 train_masksp = train_masks[:int(train_len/10*prop)]\n",
    "#                 dataND = [trainXp, trainNDp, train_turnsp, train_masksp, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "\n",
    "            testname = 'ND1'\n",
    "            testND, train_losses, dev_losses = stctrain.start_trainND(\n",
    "                *dataND, \n",
    "                **fixed_paramsND,\n",
    "                Fnum=fn, num_layers=num_layers, memory_rnn_type=None,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_losses, dev_losses)\n",
    "            datahelper.pred_to_submission(testND, bestDQAs[0], bestDQSs[0], bestDQEs[0], test_turns, testIDs, filename='{}.json'.format(testname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(testND, open('bestND190116.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('ResultPickle/memoryNDs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainDQA, train_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = True\n",
    "method = DQ.CNNCNN\n",
    "for l in [1]:\n",
    "    for rm in ['Bi-LSTM']:\n",
    "        for fn in [[512, 1024]]:\n",
    "            testname = 'ND_trainsize_{}perc'.format(prop*10)\n",
    "            print(testname, 'is started')\n",
    "        \n",
    "            bestDQA, train_lossesA, dev_lossesA = stctrain.start_trainDQ(\n",
    "                *dataDQA, \n",
    "                **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "            \n",
    "\n",
    "            bestDQE, train_lossesE, dev_lossesE = stctrain.start_trainDQ(\n",
    "                *dataDQE, \n",
    "                **fixed_paramsDQ, scoretype='DQE', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "            bestDQS, train_lossesS, dev_lossesS = stctrain.start_trainDQ(\n",
    "                *dataDQS, \n",
    "                **fixed_paramsDQ, scoretype='DQS', method=method,\n",
    "                Fnum=fn, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e\n",
    "            )\n",
    "       \n",
    "            datahelper.pred_to_submission(memoryNDs[0], bestDQA, bestDQS, bestDQE, test_turns, testIDs, filename='{}.json'.format(testname))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQAs, open('memoryDQAs.p', 'wb'))\n",
    "# pickle.dump(bestDQSs, open('memoryDQSs.p', 'wb'))\n",
    "# pickle.dump(bestDQEs, open('memoryDQEs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_to_pred(path='ReTesting/0220_wordemb_test/NoneMemory_3stackCNN_2stackRNN(best).json'):\n",
    "    import json\n",
    "    with open(path) as f:\n",
    "        test_preds_json = json.load(f)\n",
    "        \n",
    "    pred = []\n",
    "    \n",
    "    for testID in testIDs:\n",
    "        for test_pred_json in test_preds_json:\n",
    "            _id = test_pred_json['id']\n",
    "            if _id != testID:\n",
    "                continue\n",
    "            dialogue_nuggets = test_pred_json['nugget']\n",
    "            dialogue_pred = [] \n",
    "            \n",
    "            for utterance_nugget in dialogue_nuggets:\n",
    "                utterance_pred = [None] * 7\n",
    "                if len(utterance_nugget.keys()) == 4:\n",
    "                    utterance_pred[0] = utterance_nugget['CNUG*']\n",
    "                    utterance_pred[1] = utterance_nugget['CNUG']\n",
    "                    utterance_pred[2] = utterance_nugget['CNaN']\n",
    "                    utterance_pred[3] = utterance_nugget['CNUG0']\n",
    "                    utterance_pred[4] = 0.\n",
    "                    utterance_pred[5] = 0.\n",
    "                    utterance_pred[6] = 0.\n",
    "                elif len(utterance_nugget.keys()) == 3:\n",
    "                    utterance_pred[0] = 0.\n",
    "                    utterance_pred[1] = 0.\n",
    "                    utterance_pred[2] = 0.\n",
    "                    utterance_pred[3] = 0.\n",
    "                    utterance_pred[4] = utterance_nugget['HNUG*']\n",
    "                    utterance_pred[5] = utterance_nugget['HNUG']\n",
    "                    utterance_pred[6] = utterance_nugget['HNaN']\n",
    "                \n",
    "                dialogue_pred.append(utterance_pred)\n",
    "                \n",
    "            while len(dialogue_pred) < 7:\n",
    "                dialogue_pred.append([0] * 7)\n",
    "                \n",
    "            pred.append(dialogue_pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testND = submission_to_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNDmasked = [np.multiply(nd, mask) for nd, mask in zip(testND, test_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDQA_NDF += [testNDmasked]\n",
    "dataDQE_NDF += [testNDmasked]\n",
    "dataDQS_NDF += [testNDmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataDQA_NDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQNDF_trainsize_10perc is started\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.12658|0.16478\n",
      "CNNCNN|14|True|True|2_2|1024|512_1024|0.11628|0.15687\n",
      "CNNCNN|15|True|True|2_2|1024|512_1024|0.12263|0.16802\n",
      "DQNDF_trainsize_20perc is started\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.10614|0.15198\n",
      "CNNCNN|17|True|True|2_2|1024|512_1024|0.09548|0.14127\n",
      "CNNCNN|21|True|True|2_2|1024|512_1024|0.10391|0.15318\n",
      "DQNDF_trainsize_30perc is started\n",
      "CNNCNN|14|True|True|2_2|1024|512_1024|0.09980|0.14648\n",
      "CNNCNN|16|True|True|2_2|1024|512_1024|0.09111|0.13518\n",
      "CNNCNN|8|True|True|2_2|1024|512_1024|0.12357|0.16549\n",
      "DQNDF_trainsize_40perc is started\n",
      "CNNCNN|13|True|True|2_2|1024|512_1024|0.08893|0.13366\n",
      "CNNCNN|15|True|True|2_2|1024|512_1024|0.08648|0.13057\n",
      "CNNCNN|15|True|True|2_2|1024|512_1024|0.09441|0.14260\n",
      "DQNDF_trainsize_50perc is started\n",
      "CNNCNN|15|True|True|2_2|1024|512_1024|0.08880|0.13479\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08268|0.12327\n",
      "CNNCNN|10|True|True|2_2|1024|512_1024|0.09455|0.14574\n",
      "DQNDF_trainsize_60perc is started\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08847|0.13479\n",
      "CNNCNN|14|True|True|2_2|1024|512_1024|0.08037|0.12335\n",
      "CNNCNN|7|True|True|2_2|1024|512_1024|0.10134|0.14473\n",
      "DQNDF_trainsize_70perc is started\n",
      "CNNCNN|10|True|True|2_2|1024|512_1024|0.08560|0.13047\n",
      "CNNCNN|9|True|True|2_2|1024|512_1024|0.08345|0.12446\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08424|0.13175\n",
      "DQNDF_trainsize_80perc is started\n",
      "CNNCNN|9|True|True|2_2|1024|512_1024|0.08849|0.13223\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08024|0.12352\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08795|0.13782\n",
      "DQNDF_trainsize_90perc is started\n",
      "CNNCNN|8|True|True|2_2|1024|512_1024|0.08559|0.12830\n",
      "CNNCNN|10|True|True|2_2|1024|512_1024|0.08248|0.12357\n",
      "CNNCNN|12|True|True|2_2|1024|512_1024|0.08548|0.13438\n",
      "DQNDF_trainsize_100perc is started\n",
      "CNNCNN|10|True|True|2_2|1024|512_1024|0.08254|0.12555\n",
      "CNNCNN|9|True|True|2_2|1024|512_1024|0.07899|0.11964\n",
      "CNNCNN|10|True|True|2_2|1024|512_1024|0.08703|0.13316\n"
     ]
    }
   ],
   "source": [
    "method = DQNDF.CNNCNN\n",
    "e = True\n",
    "testND = np.asarray(testND)\n",
    "\n",
    "for prop in range(1, 11):\n",
    "    for mr in ['Bi-LSTM']:\n",
    "        for fnum in [[512, 1024]]:\n",
    "            for num_layers in [1]:\n",
    "                testname = 'DQNDF_trainsize_{}perc'.format(prop*10)\n",
    "                print(testname, 'is started')\n",
    "                \n",
    "                trainXp = trainX[:int(train_len/10*prop)]\n",
    "                train_turnsp = train_turns[:int(train_len/10*prop)]\n",
    "                trainNDp = trainND[:int(train_len/10*prop)]\n",
    "                \n",
    "                trainDQAp = trainDQA[:int(train_len/10*prop)]      \n",
    "                dataDQA_NDF = [trainXp, trainDQAp, train_turnsp, trainNDp, devX, devDQA, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "                trainDQEp = trainDQE[:int(train_len/10*prop)]         \n",
    "                dataDQE_NDF = [trainXp, trainDQEp, train_turnsp, trainNDp, devX, devDQE, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "                trainDQSp = trainDQA[:int(train_len/10*prop)]              \n",
    "                dataDQS_NDF = [trainXp, trainDQSp, train_turnsp, trainNDp, devX, devDQS, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "                \n",
    "                \n",
    "                bestDQNDFA, train_lossesA, dev_lossesA = stctrain.start_trainDQ_NDF(\n",
    "                    *dataDQA_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQA', method=method,\n",
    "                    Fnum=fnum, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e,\n",
    "                )\n",
    "\n",
    "                bestDQNDFE, train_lossesE, dev_lossesE = stctrain.start_trainDQ_NDF(\n",
    "                    *dataDQE_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQE',\n",
    "                    Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e,\n",
    "                )\n",
    "\n",
    "                bestDQNDFS, train_lossesS, dev_lossesS = stctrain.start_trainDQ_NDF(\n",
    "                    *dataDQS_NDF, \n",
    "                    **fixed_paramsDQ, scoretype='DQS', \n",
    "                    Fnum=fnum, method=method, memory_rnn_type=mr, num_layers=num_layers,\n",
    "                    evaluate=e\n",
    "                )\n",
    "\n",
    "                datahelper.pred_to_submission(testND, bestDQNDFA, bestDQNDFS, bestDQNDFE, test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQANDFs, open('memoryDQANDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQSNDFs, open('memoryDQSNDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQENDFs, open('memoryDQENDFs.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
