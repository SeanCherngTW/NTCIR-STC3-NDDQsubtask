{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import param\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import stctrain\n",
    "import datahelper\n",
    "import stctokenizer\n",
    "import nuggetdetection as ND\n",
    "import dialogquality as DQ\n",
    "import dialogquality_ndfeature as DQNDF\n",
    "import stcevaluation as STCE\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "doclen = param.doclen\n",
    "embsize = param.embsize\n",
    "max_sent = param.max_sent\n",
    "NDclasses = param.NDclasses\n",
    "DQclasses = param.DQclasses\n",
    "sentembsize = param.sentembsize\n",
    "\n",
    "REMOVE_STOPWORDS = False\n",
    "TO_LOWER = True\n",
    "TOKEN_TYPE = 'nltk'\n",
    "EMB = 'stc' # glove or stc\n",
    "\n",
    "datahelper = datahelper.DataHelper(embedding_path=\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "stctokenizer = stctokenizer.STCTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# corpus = datahelper.prepare_word_embedding_corpus(\n",
    "#     '../data/text8', \n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "# )\n",
    "\n",
    "# wordemb_model = Word2Vec(corpus, size=200, min_count=0, workers=4, iter=30, window=8)\n",
    "# word_vectors = wordemb_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word_vectors.save(\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "# datahelper.set_word_vectors(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read Corpus & Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    trainX, trainND, trainDQ, train_turns, train_masks = datahelper.get_model_train_data(\n",
    "        'train',\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "    )\n",
    "\n",
    "    devX, devND, devDQ, dev_turns, dev_masks = datahelper.get_model_train_data(\n",
    "        'dev',\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "    )\n",
    "\n",
    "    testX, test_turns, test_masks = datahelper.get_model_test_data(\n",
    "        TOKEN_TYPE, \n",
    "        REMOVE_STOPWORDS, \n",
    "        TO_LOWER,\n",
    "        EMB,\n",
    "    )\n",
    "\n",
    "    testIDs = datahelper.testIDs\n",
    "    trainDQA = [item['A'] for item in trainDQ]\n",
    "    trainDQS = [item['S'] for item in trainDQ]\n",
    "    trainDQE = [item['E'] for item in trainDQ]\n",
    "    devDQA = [item['A'] for item in devDQ]\n",
    "    devDQS = [item['S'] for item in devDQ]\n",
    "    devDQE = [item['E'] for item in devDQ]\n",
    "\n",
    "    dataND = [trainX, trainND, train_turns, train_masks, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "    dataDQA = [trainX, trainDQA, train_turns, devX, devDQA, dev_turns, testX, test_turns]\n",
    "    dataDQS = [trainX, trainDQS, train_turns, devX, devDQS, dev_turns, testX, test_turns]\n",
    "    dataDQE = [trainX, trainDQE, train_turns, devX, devDQE, dev_turns, testX, test_turns]\n",
    "\n",
    "    return dataND, dataDQA, dataDQS, dataDQE, testX, test_turns, test_masks, testIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataND, dataDQA, dataDQS, dataDQE, testX, test_turns, test_masks, testIDs = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "es = 3\n",
    "fixed_paramsND  = {\n",
    "    'epoch':100, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':30,\n",
    "    'lr':5e-4,\n",
    "    'kp':1, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,2], \n",
    "    'gating':False, \n",
    "    'bn':True, \n",
    "    'method':ND.CNNRNN,\n",
    "} \n",
    "\n",
    "fixed_paramsDQ = {\n",
    "    'epoch':50, \n",
    "    'early_stopping':es, \n",
    "    'batch_size':40, \n",
    "    'kp':1, \n",
    "    'lr':0.001, \n",
    "    'hiddens':1024, \n",
    "    'Fsize':[2,2],\n",
    "}\n",
    "\n",
    "fixed_paramsDQA = fixed_paramsDQ.update({'scoretype':'DQA'})\n",
    "fixed_paramsDQS = fixed_paramsDQ.update({'scoretype':'DQS'})\n",
    "fixed_paramsDQE = fixed_paramsDQ.update({'scoretype':'DQE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def show_train_history(title, train, valid, earlystop=es):\n",
    "    epoch = len(train)\n",
    "    best = epoch-earlystop\n",
    "    x = [i for i in range(1, epoch + 1)]\n",
    "    plt.figure(figsize=(5,12))\n",
    "    ax = plt.figure().gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.plot(x, train, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(x, valid, marker='o', linestyle='-', color='r')\n",
    "    plt.axvline(best, color='black')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BEST_PATH = 'ResultPickle/'\n",
    "# bestND = pickle.load(open(BEST_PATH + 'bestND.p', \"rb\"))\n",
    "bestDQAs = pickle.load(open(BEST_PATH + 'memoryDQAs.p', \"rb\"))\n",
    "bestDQSs = pickle.load(open(BEST_PATH + 'memoryDQSs.p', \"rb\"))\n",
    "bestDQEs = pickle.load(open(BEST_PATH + 'memoryDQEs.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = datahelper.prepare_word_embedding_corpus(\n",
    "    '../data/text8', \n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter15_lr0.0005_sg0_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|14|False|True|2_2|1024|256_512_1024|1|0.0257|0.0958\n",
      "iter15_lr0.0005_sg1_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|10|False|True|2_2|1024|256_512_1024|1|0.0285|0.1015\n",
      "iter15_lr0.0005_sg0_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|14|False|True|2_2|1024|256_512_1024|1|0.0261|0.0967\n",
      "iter15_lr0.0005_sg1_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|13|False|True|2_2|1024|256_512_1024|1|0.0262|0.0972\n",
      "iter20_lr0.0005_sg0_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|8|False|True|2_2|1024|256_512_1024|1|0.0337|0.1084\n",
      "iter20_lr0.0005_sg1_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|16|False|True|2_2|1024|256_512_1024|1|0.0249|0.0961\n",
      "iter20_lr0.0005_sg0_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|12|False|True|2_2|1024|256_512_1024|1|0.0272|0.0996\n",
      "iter20_lr0.0005_sg1_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|11|False|True|2_2|1024|256_512_1024|1|0.0275|0.1014\n",
      "iter25_lr0.0005_sg0_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|9|False|True|2_2|1024|256_512_1024|1|0.0306|0.1024\n",
      "iter25_lr0.0005_sg1_ws5\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|15|False|True|2_2|1024|256_512_1024|1|0.0259|0.0979\n",
      "iter25_lr0.0005_sg0_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|13|False|True|2_2|1024|256_512_1024|1|0.0254|0.0942\n",
      "iter25_lr0.0005_sg1_ws8\n",
      "x.shape (?, 7, 150, 100)\n",
      "CNNRNN|15|False|True|2_2|1024|256_512_1024|1|0.0249|0.0951\n"
     ]
    }
   ],
   "source": [
    "size=100\n",
    "\n",
    "for i in [15,20,25]:\n",
    "    for ws in [5, 8]:\n",
    "        for sg in [0, 1]:\n",
    "            wordemb_model = Word2Vec(corpus, size=size, min_count=0, workers=4, iter=i, sg=sg, window=ws)\n",
    "            word_vectors = wordemb_model.wv\n",
    "            datahelper.set_word_vectors(word_vectors)\n",
    "            dataND, dataDQA, dataDQS, dataDQE, testX, test_turns, test_masks, testIDs = get_data()\n",
    "\n",
    "            e = True\n",
    "            for fn in [[256, 512, 1024]]:\n",
    "                for num_layers in [2]:\n",
    "                    testname = 'iter{}_lr{}_sg{}_ws{}'.format(i, lr,sg,ws)\n",
    "    #                 testname = 'emb{}_iter{}_Memory{}_GatingFalse_CNNRNN_{}stack_rnnLayer{}'.format(size, i, mr, len(fn), num_layers)\n",
    "                    print(testname)\n",
    "                    testND, train_losses, dev_losses = stctrain.start_trainND(\n",
    "                        *dataND, \n",
    "                        **fixed_paramsND,\n",
    "                        Fnum=fn, num_layers=num_layers, memory_rnn_type=None,\n",
    "                        evaluate=e,\n",
    "                    )\n",
    "\n",
    "        #             show_train_history(testname, train_losses, dev_losses)\n",
    "                    datahelper.pred_to_submission(testND, bestDQAs[0], bestDQSs[0], bestDQEs[0], test_turns, testIDs, filename='{}.json'.format(testname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(testND, open('bestND190116.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-30d9529ff51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('ResultPickle/memoryNDs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = True\n",
    "for rm in ['Bi-GRU', 'Bi-LSTM']:\n",
    "    for l in [1, 2, 3]:\n",
    "        for fn in [[1024], [512, 1024], [256, 512, 1024]]:\n",
    "            testname = 'A-GatingTrue_{}stack_Memory{}_RNNLayer{}'.format(len(fn), rm, l)\n",
    "            print(testname)\n",
    "            bestDQA, train_lossesA, dev_lossesA = stctrain.start_trainDQ(\n",
    "                *dataDQA, \n",
    "                **fixed_paramsDQA, \n",
    "                Fnum=fn, gating=True, bn=True, method=DQ.CNNCNN, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesA, dev_lossesA)\n",
    "\n",
    "            testname = 'E-GatingTrue_{}stack_Memory{}_RNNLayer{}'.format(len(fn), rm, l)\n",
    "            print(testname)\n",
    "            bestDQE, train_lossesE, dev_lossesE = stctrain.start_trainDQ(\n",
    "                *dataDQE, \n",
    "                **fixed_paramsDQE, \n",
    "                Fnum=fn, gating=True, bn=True, method=DQ.CNNCNN, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesE, dev_lossesE)\n",
    "\n",
    "            testname = 'S-GatingTrue_{}stack_Memory{}_RNNLayer{}'.format(len(fn), rm, l)\n",
    "            print(testname)\n",
    "            bestDQS, train_lossesS, dev_lossesS = stctrain.start_trainDQ(\n",
    "                *dataDQS, \n",
    "                **fixed_paramsDQS, \n",
    "                Fnum=fn, gating=True, bn=True, method=DQ.CNNCNN, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesS, dev_lossesS)\n",
    "\n",
    "            testname = 'GatingTrue_{}stack_Memory{}_RNNLayer{}'.format(len(fn), rm, l)\n",
    "            datahelper.pred_to_submission(memoryNDs[0], bestDQA, bestDQS, bestDQE, test_turns, testIDs, filename='{}.json'.format(testname))\n",
    "            print(testname, 'is saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQAs, open('memoryDQAs.p', 'wb'))\n",
    "# pickle.dump(bestDQSs, open('memoryDQSs.p', 'wb'))\n",
    "# pickle.dump(bestDQEs, open('memoryDQEs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "memoryND = pickle.load(open('ResultPickle/bestND190116.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testNDmasked = [np.multiply(nd, mask) for nd, mask in zip(memoryND, test_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataDQA_NDF = [trainX, trainDQA, train_turns, trainND, devX, devDQA, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "dataDQS_NDF = [trainX, trainDQS, train_turns, trainND, devX, devDQS, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "dataDQE_NDF = [trainX, trainDQE, train_turns, trainND, devX, devDQE, dev_turns, devND, testX, test_turns, testNDmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "method = DQNDF.CNNCNN\n",
    "e = True\n",
    "for rm in [None]:\n",
    "    for l in [1]:\n",
    "        for fn in [[512, 1024]]:\n",
    "            testname = 'DQNDFA-GatingTrue_{}stack_Memory{}_{}{}'.format(len(fn), rm, l, str(method).split()[1])\n",
    "            print(testname)\n",
    "            bestDQNDFA, train_lossesA, dev_lossesA = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQA_NDF, \n",
    "                **fixed_paramsDQA, \n",
    "                Fnum=fn, gating=True, bn=True, method=method, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesA, dev_lossesA)\n",
    "\n",
    "            testname = 'DQNDFE-GatingTrue_{}stack_Memory{}_{}{}'.format(len(fn), rm, l, str(method).split()[1])\n",
    "            print(testname)\n",
    "            bestDQNDFE, train_lossesE, dev_lossesE = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQE_NDF, \n",
    "                **fixed_paramsDQE, \n",
    "                Fnum=fn, gating=True, bn=True, method=method, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e,\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesE, dev_lossesE)\n",
    "\n",
    "            testname = 'DQNDFS-GatingTrue_{}stack_Memory{}_{}{}'.format(len(fn), rm, l, str(method).split()[1])\n",
    "            print(testname)\n",
    "            bestDQNDFS, train_lossesS, dev_lossesS = stctrain.start_trainDQ_NDF(\n",
    "                *dataDQS_NDF, \n",
    "                **fixed_paramsDQS, \n",
    "                Fnum=fn, gating=True, bn=True, method=method, memory_rnn_type=rm, num_layers=l,\n",
    "                evaluate=e\n",
    "            )\n",
    "\n",
    "#             show_train_history(testname, train_lossesS, dev_lossesS)\n",
    "\n",
    "            testname = 'DQNDF-GatingTrue_{}stack_Memory{}_{}{}'.format(len(fn), rm, l, str(method).split()[1])\n",
    "            datahelper.pred_to_submission(memoryND, bestDQNDFA, bestDQNDFS, bestDQNDFE, test_turns, testIDs, filename='{}.json'.format(testname))\n",
    "            print(testname, 'is saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQANDFs, open('memoryDQANDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQSNDFs, open('memoryDQSNDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQENDFs, open('memoryDQENDFs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data settings.\n",
    "num_examples = 10\n",
    "num_words = 20\n",
    "num_features = 100\n",
    "num_tags = 5\n",
    "\n",
    "# Random features.\n",
    "x = np.random.rand(num_examples, num_words, num_features).astype(np.float32)\n",
    "\n",
    "# Random tag indices representing the gold sequence.\n",
    "y = np.random.randint(num_tags, size=[num_examples, num_words]).astype(np.int32)\n",
    "\n",
    "print(y)\n",
    "\n",
    "# All sequences in this example have the same length, but they can be variable in a real model.\n",
    "sequence_lengths = np.full(num_examples, num_words - 1, dtype=np.int32)\n",
    "print(sequence_lengths)\n",
    "\n",
    "# Train and evaluate the model.\n",
    "with tf.Graph().as_default():\n",
    "  with tf.Session() as session:\n",
    "    # Add the data to the TensorFlow graph.\n",
    "    x_t = tf.constant(x)\n",
    "    y_t = tf.constant(y)\n",
    "    sequence_lengths_t = tf.constant(sequence_lengths)\n",
    "\n",
    "    # Compute unary scores from a linear layer.\n",
    "    weights = tf.get_variable(\"weights\", [num_features, num_tags])\n",
    "    matricized_x_t = tf.reshape(x_t, [-1, num_features])\n",
    "    matricized_unary_scores = tf.matmul(matricized_x_t, weights)\n",
    "    unary_scores = tf.reshape(matricized_unary_scores,\n",
    "                              [num_examples, num_words, num_tags])\n",
    "\n",
    "    # Compute the log-likelihood of the gold sequences and keep the transition\n",
    "    # params for inference at test time.\n",
    "    print(unary_scores.shape)\n",
    "    print(y_t.shape)\n",
    "    print(sequence_lengths_t.shape)\n",
    "    log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(\n",
    "        unary_scores, y_t, sequence_lengths_t)\n",
    "\n",
    "    # Add a training op to tune the parameters.\n",
    "    loss = tf.reduce_mean(-log_likelihood)\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "    # Train for a fixed number of iterations.\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "      tf_unary_scores, tf_transition_params, _ = session.run(\n",
    "          [unary_scores, transition_params, train_op])\n",
    "      if i % 100 == 0:\n",
    "        correct_labels = 0\n",
    "        total_labels = 0\n",
    "        for tf_unary_scores_, y_, sequence_length_ in zip(tf_unary_scores, y,\n",
    "                                                          sequence_lengths):\n",
    "          # Remove padding from the scores and tag sequence.\n",
    "          tf_unary_scores_ = tf_unary_scores_[:sequence_length_]\n",
    "          y_ = y_[:sequence_length_]\n",
    "\n",
    "          # Compute the highest scoring sequence.\n",
    "          viterbi_sequence, _ = tf.contrib.crf.viterbi_decode(\n",
    "              tf_unary_scores_, tf_transition_params)\n",
    "\n",
    "          # Evaluate word-level accuracy.\n",
    "          correct_labels += np.sum(np.equal(viterbi_sequence, y_))\n",
    "          total_labels += sequence_length_\n",
    "        accuracy = 100.0 * correct_labels / float(total_labels)\n",
    "        print(\"Accuracy: %.2f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
