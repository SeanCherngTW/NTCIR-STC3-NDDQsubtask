{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import timeit\n",
    "import random\n",
    "import param\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import stctrain\n",
    "import datahelper\n",
    "import stctokenizer\n",
    "import nuggetdetection as ND\n",
    "import dialogquality as DQ\n",
    "import dialogquality_ndfeature as DQNDF\n",
    "import stcevaluation as STCE\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Word2VecKeyedVectors object from ../embedding/STCWiki/STCWiki_mincount0.model.bin\n",
      "INFO:gensim.utils:loading vectors from ../embedding/STCWiki/STCWiki_mincount0.model.bin.vectors.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute vectors_norm to None\n",
      "INFO:gensim.utils:loaded ../embedding/STCWiki/STCWiki_mincount0.model.bin\n"
     ]
    }
   ],
   "source": [
    "doclen = param.doclen\n",
    "embsize = param.embsize\n",
    "max_sent = param.max_sent\n",
    "NDclasses = param.NDclasses\n",
    "DQclasses = param.DQclasses\n",
    "sentembsize = param.sentembsize\n",
    "\n",
    "REMOVE_STOPWORDS = False\n",
    "TO_LOWER = True\n",
    "TOKEN_TYPE = 'nltk'\n",
    "\n",
    "datahelper = datahelper.DataHelper(embedding_path=\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "stctokenizer = stctokenizer.STCTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# corpus = datahelper.prepare_word_embedding_corpus(\n",
    "#     '../data/text8', \n",
    "#     TOKEN_TYPE, \n",
    "#     REMOVE_STOPWORDS, \n",
    "#     TO_LOWER,\n",
    "# )\n",
    "\n",
    "# wordemb_model = Word2Vec(corpus, size=300, min_count=0, workers=4, iter=25)\n",
    "# word_vectors = wordemb_model.wv\n",
    "# datahelper.test_w2v_model(word_vectors, word='problem', topn=10)\n",
    "\n",
    "# 儲存訓練好的word2vec模型，因為已經訓練並儲存好了所以註解掉\n",
    "# word_vectors.save(\"../embedding/STCWiki/STCWiki_mincount0.model.bin\")\n",
    "# datahelper.set_word_vectors(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Read Corpus & Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:corpus word2vec:Training data unknown words count: 0\n",
      "INFO:corpus word2vec:Training data unknown words count: 0\n",
      "INFO:corpus word2vec:Testing data unknown words count: 0\n"
     ]
    }
   ],
   "source": [
    "trainX, trainND, trainDQ, train_turns, train_masks = datahelper.get_model_train_data(\n",
    "    'train',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    ")\n",
    "\n",
    "devX, devND, devDQ, dev_turns, dev_masks = datahelper.get_model_train_data(\n",
    "    'dev',\n",
    "    TOKEN_TYPE, \n",
    "    REMOVE_STOPWORDS, \n",
    "    TO_LOWER,\n",
    ")\n",
    "\n",
    "testX, test_turns, test_masks = datahelper.get_model_test_data(token_type='nltk', remove_stopwords=False, to_lower=True)\n",
    "\n",
    "testIDs = datahelper.testIDs\n",
    "trainDQA = [item['A'] for item in trainDQ]\n",
    "trainDQS = [item['S'] for item in trainDQ]\n",
    "trainDQE = [item['E'] for item in trainDQ]\n",
    "devDQA = [item['A'] for item in devDQ]\n",
    "devDQS = [item['S'] for item in devDQ]\n",
    "devDQE = [item['E'] for item in devDQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataND = [trainX, trainND, train_turns, train_masks, devX, devND, dev_turns, dev_masks, testX, test_turns, test_masks]\n",
    "dataDQA = [trainX, trainDQA, train_turns, devX, devDQA, dev_turns, testX, test_turns]\n",
    "dataDQS = [trainX, trainDQS, train_turns, devX, devDQS, dev_turns, testX, test_turns]\n",
    "dataDQE = [trainX, trainDQE, train_turns, devX, devDQE, dev_turns, testX, test_turns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fixed_paramsND  = {'epoch':50, 'early_stopping':50, 'batch_size':30, 'lr':0.0005, 'kp':1, 'hiddens':1024, 'Fsize':[2,2]} \n",
    "fixed_paramsDQA = {'scoretype':'DQA', 'epoch':50, 'early_stopping':3, 'batch_size':40, 'lr':0.001, 'kp':1, 'hiddens':1024, 'Fsize':[2,2]} \n",
    "fixed_paramsDQS = {'scoretype':'DQS', 'epoch':50, 'early_stopping':3, 'batch_size':40, 'lr':0.001, 'kp':1, 'hiddens':1024, 'Fsize':[2,2]} \n",
    "fixed_paramsDQE = {'scoretype':'DQE', 'epoch':50, 'early_stopping':3, 'batch_size':40, 'lr':0.001, 'kp':1, 'hiddens':1024, 'Fsize':[2,2]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_train_history(title, train, valid):\n",
    "    x = [i for i in range(1, len(train)+1)]\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    plt.plot(x, train, marker='o', linestyle='-', color='b')\n",
    "    plt.plot(x, valid, marker='o', linestyle='-', color='r')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bestNDs = []\n",
    "train_losses_list = []\n",
    "dev_losses_list = []\n",
    "e = False\n",
    "for fn in [[256], [256,512], [256,512,1024]]:\n",
    "    testND, train_losses, dev_losses = stctrain.start_trainND(\n",
    "        *dataND, \n",
    "        **fixed_paramsND, \n",
    "        Fnum=fn, gating=False, bn=True, method=ND.CNNRNN, \n",
    "        evaluate=e,\n",
    "    )\n",
    "\n",
    "    bestNDs.append(testND)\n",
    "    train_losses_list.append(train_losses)\n",
    "    dev_losses_list.append(dev_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "show_train_history('1-stack CNN + RNN', train_losses_list[0], dev_losses_list[0])\n",
    "show_train_history('2-stack CNN + RNN', train_losses_list[1], dev_losses_list[1])\n",
    "show_train_history('3-stack CNN + RNN', train_losses_list[2], dev_losses_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(bestNDs, open('memoryND_Labels.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test DQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Training:CNNCNN|14|True|True|2_2|1024|512_1024|0.08473|0.13266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "bestDQAs = []\n",
    "bestDQSs = []\n",
    "bestDQEs = []\n",
    "\n",
    "train_losses_listA = []\n",
    "dev_losses_listA = []\n",
    "e = False\n",
    "for fn in [[512, 1024], [256, 512, 1024]]:\n",
    "    for m in [DQ.CNNCNN, DQ.CNNRNN]:\n",
    "        bestDQA, train_lossesA, dev_lossesA = stctrain.start_trainDQ(\n",
    "            *dataDQA, \n",
    "            **fixed_paramsDQA, \n",
    "            Fnum=fn, gating=True, bn=True, method=m, \n",
    "            evaluate=e,\n",
    "        )\n",
    "\n",
    "#         bestDQS = stctrain.start_trainDQ(\n",
    "#             *dataDQS, \n",
    "#             **fixed_paramsDQS, \n",
    "#             Fnum=fn, gating=True, bn=bn, method=DQ.CNNRNN, \n",
    "#             evaluate=e\n",
    "#         )\n",
    "\n",
    "#         bestDQE = stctrain.start_trainDQ(\n",
    "#             *dataDQE, \n",
    "#             **fixed_paramsDQE, \n",
    "#             Fnum=fn, gating=True, bn=bn, method=DQ.CNNRNN, \n",
    "#             evaluate=e,\n",
    "#         )\n",
    "        train_losses_listA.append(train_lossesA)\n",
    "        dev_losses_listA.append(dev_lossesA)\n",
    "        bestDQAs.append(bestDQA)\n",
    "    #         bestDQSs.append(bestDQS)\n",
    "    #         bestDQEs.append(bestDQE)\n",
    "        print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_train_history('2-stack CNN + CNN', train_losses_listA[0], dev_losses_listA[0])\n",
    "show_train_history('2-stack CNN + RNN', train_losses_listA[1], dev_losses_listA[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQAs, open('memoryDQAs.p', 'wb'))\n",
    "# pickle.dump(bestDQSs, open('memoryDQSs.p', 'wb'))\n",
    "# pickle.dump(bestDQEs, open('memoryDQEs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test NDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('memoryNDs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testNDmasked = [np.multiply(nd, mask) for nd, mask in zip(memoryNDs[1], test_masks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataDQA_NDF = [trainX, trainDQA, train_turns, trainND, devX, devDQA, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "dataDQS_NDF = [trainX, trainDQS, train_turns, trainND, devX, devDQS, dev_turns, devND, testX, test_turns, testNDmasked]\n",
    "dataDQE_NDF = [trainX, trainDQE, train_turns, trainND, devX, devDQE, dev_turns, devND, testX, test_turns, testNDmasked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bestDQANDFs = []\n",
    "bestDQSNDFs = []\n",
    "bestDQENDFs = []\n",
    "e = True\n",
    "for fn in [[128, 256, 512, 1024], [128, 256, 512, 1024, 1024], [128, 256, 512, 1024, 1024, 1024]]:\n",
    "#     bestDQANDF = stctrain.start_trainDQ_NDF(\n",
    "#         *dataDQA_NDF, \n",
    "#         **fixed_paramsDQA, \n",
    "#         Fnum=fn, gating=True, bn=bn, method=DQNDF.CNNRNN, \n",
    "#         evaluate=e,\n",
    "#     )\n",
    "\n",
    "    bestDQSNDF = stctrain.start_trainDQ_NDF(\n",
    "        *dataDQS_NDF, \n",
    "        **fixed_paramsDQS, \n",
    "        Fnum=fn, gating=True, bn=True, method=DQNDF.CNNRNN, \n",
    "        evaluate=e\n",
    "    )\n",
    "\n",
    "    bestDQENDF = stctrain.start_trainDQ_NDF(\n",
    "        *dataDQE_NDF, \n",
    "        **fixed_paramsDQE, \n",
    "        Fnum=fn, gating=True, bn=True, method=DQNDF.CNNRNN, \n",
    "        evaluate=e,\n",
    "    )\n",
    "\n",
    "#     bestDQANDFs.append(bestDQANDF)\n",
    "    bestDQSNDFs.append(bestDQSNDF)\n",
    "    bestDQENDFs.append(bestDQENDF)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(bestDQANDFs, open('memoryDQANDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQSNDFs, open('memoryDQSNDFs.p', 'wb'))\n",
    "# pickle.dump(bestDQENDFs, open('memoryDQENDFs.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "memoryNDs = pickle.load(open('memoryNDs.p', 'rb'))\n",
    "print('ND len', len(memoryNDs))\n",
    "\n",
    "bestDQAs = pickle.load(open('memoryDQANDFs.p', 'rb'))\n",
    "bestDQSs = pickle.load(open('memoryDQSNDFs.p', 'rb'))\n",
    "bestDQEs = pickle.load(open('memoryDQENDFs.p', 'rb'))\n",
    "print('DQ len', len(bestDQAs))\n",
    "\n",
    "bestDQAsNDF = pickle.load(open('memoryDQANDFs.p', 'rb'))\n",
    "bestDQSsNDF = pickle.load(open('memoryDQSNDFs.p', 'rb'))\n",
    "bestDQEsNDF = pickle.load(open('memoryDQENDFs.p', 'rb'))\n",
    "print('DQNDF len', len(bestDQAsNDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# submission[0] = ND[1], DQA[1], DQSNDF[3], DQENDF[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testday = '190103'\n",
    "i = 0\n",
    "datahelper.pred_to_submission(\n",
    "    memoryNDs[1], \n",
    "    bestDQAs[1], bestDQSsNDF[3], bestDQEsNDF[3], \n",
    "    test_turns, testIDs, \n",
    "    filename='Testing/{}upload/{}.json'.format(testday, i),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testday = 'TESTDAY'\n",
    "BEST_PATH = 'best_{}/'.format(testday)\n",
    "bestND = pickle.load(open(BEST_PATH + 'bestND.p', \"rb\"))\n",
    "bestDQAs = pickle.load(open(BEST_PATH + 'bestDQAs.p', \"rb\"))\n",
    "bestDQSs = pickle.load(open(BEST_PATH + 'bestDQSs.p', \"rb\"))\n",
    "bestDQEs = pickle.load(open(BEST_PATH + 'bestDQEs.p', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred_to_submission(bestNDs[0], bestDQAs[0], bestDQSs[0], bestDQEs[0], test_turns, testIDs, filename='nd3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(np.array([[1, 2], [3, 4], [5, 6]]), dtype=tf.float32)\n",
    "b = tf.constant(np.array([[1, 2], [3, 4], [5, 6]]), dtype=tf.float32)\n",
    "# c = tf.tensordot( a, b , axes=1)\n",
    "c = tf.reduce_sum( tf.multiply( a, b ), axis=1)\n",
    "# d = tf.scalar_mul([1,2], a)\n",
    "\n",
    "x = tf.constant([[5.0, 10.0, 15, 20], [5,10,15,20]])\n",
    "y = tf.multiply(x, [1,2,3,4])\n",
    "\n",
    "# ? = 3\n",
    "a_w = tf.constant(np.array([1,2,3,4,5]), dtype=tf.float32)\n",
    "o_m = tf.constant(np.array([[1,2,3,4,5,6,7], \n",
    "                            [1,2,3,4,5,6,7],\n",
    "                            [1,2,3,4,5,6,7],\n",
    "                            [1,2,3,4,5,6,7],\n",
    "                            [1,2,3,4,5,6,7]]), \n",
    "                            dtype=tf.float32,\n",
    "                           )\n",
    "b = tf.constant([2,3])\n",
    "c = tf.reshape(b, [-1,1,1])\n",
    "# out = tf.scalar_mul(a_w, o_m)\n",
    "# out = tf.reduce_sum(tf.multiply(a_w, o_m), axis=0)\n",
    "\n",
    "stack = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "#     output = sess.run(out)\n",
    "    print(sess.run(c))\n",
    "#     output = sess.run(d)\n",
    "#     print(output)\n",
    "#     print(sess.run(y))\n",
    "#     print(sess.run(tf.stack(stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1,1,1], [2,2,2], [3,3,3], [4,4,4], [5,5,5], [6,6,6], [7,7,7]])  # 7x3 (7x1024)\n",
    "b = tf.reduce_mean(a, axis=0)\n",
    "# b = tf.constant([1,2,3,4,5,6,7]) # (7, )\n",
    "# c = tf.reshape(b, [-1,1])\n",
    "# d = tf.multiply(a,c)\n",
    "with tf.Session() as sess:\n",
    "#     print(sess.run(a).shape)\n",
    "    print(sess.run(b))\n",
    "#     print(sess.run(d).shape)\n",
    "#     print(sess.run(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
